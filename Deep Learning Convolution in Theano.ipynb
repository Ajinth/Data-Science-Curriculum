{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# to keep track of how long it takes\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our basic helper functions will give us the error rate, the rectifier linear unit function, and an indicator matrix for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)\n",
    "\n",
    "def relu(a):\n",
    "    return a * (a > 0)\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our convpool function first performs the convolution on our input matrix given our filters. We downsample each feature map individually using maxpooling, and we set the poolsize to (2, 2). To add the bias term, we need to reshape our bias variable to a tensor of shape (1, n_filters, 1, 1), where each bias wil be broadcasted across mini-batches and feature map width and height. Our activation function will be the ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convpool(X, W, b, poolsize=(2, 2)):\n",
    "    conv_out = conv2d(input=X, filters=W)\n",
    "\n",
    "    pooled_out = pool.pool_2d(\n",
    "        input=conv_out,\n",
    "        ds=poolsize,\n",
    "        ignore_border=True\n",
    "    )\n",
    "\n",
    "    return relu(pooled_out + b.dimshuffle('x', 0, 'x', 'x'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The way we always initialize weights is random normal / sqrt(fan in + fan out). The key point is it's random with a variance restricted by the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is our weight initialization function, which takes in the dimensions\n",
    "def init_filter(shape, poolsz):\n",
    "    # this is the fan in plus fan out\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[1:]) + shape[0]*np.prod(shape[2:] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we import our MNIST data, normalize it, and partition it into train and test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('Data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_data(data):\n",
    "    data = data.as_matrix().astype(np.float32)\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:]\n",
    "    mu = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    np.place(std, std == 0, 1)\n",
    "    X = (X - mu) / std\n",
    "    Y = data[:, 0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(len(X), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our hyperparameters, and we will add L2 regularization along with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 30\n",
    "print_period = 10\n",
    "\n",
    "lr = np.float32(0.00004)\n",
    "reg = np.float32(0.01)\n",
    "mu = np.float32(0.9)\n",
    "\n",
    "N = Xtrain.shape[0]\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "\n",
    "M = 500\n",
    "K = 10\n",
    "poolsz = (2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first convolution will have 20 feature maps, while our second convolution will have 50 feature maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after conv will be of dimension 32 - 5 + 1 = 28\n",
    "# after downsample 28 / 2 = 14\n",
    "W1_shape = (20, 1, 5, 5) # (num_feature_maps, num_color_channels, filter_width, filter_height)\n",
    "W1_init = init_filter(W1_shape, poolsz)\n",
    "b1_init = np.zeros(W1_shape[0], dtype=np.float32) # one bias per output feature map\n",
    "\n",
    "# after conv will be of dimension 14 - 5 + 1 = 10\n",
    "# after downsample 10 / 2 = 5\n",
    "W2_shape = (50, 20, 5, 5) # (num_feature_maps, old_num_feature_maps, filter_width, filter_height)\n",
    "W2_init = init_filter(W2_shape, poolsz)\n",
    "b2_init = np.zeros(W2_shape[0], dtype=np.float32)\n",
    "\n",
    "# vanilla ANN weights\n",
    "W3_init = np.random.randn(W2_shape[0]*4*4, M) / np.sqrt(W2_shape[0]*4*4 + M)\n",
    "b3_init = np.zeros(M, dtype=np.float32)\n",
    "W4_init = np.random.randn(M, K) / np.sqrt(M + K)\n",
    "b4_init = np.zeros(K, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our shared variables, which include the weights and bias terms as well as the momentum changes for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2: define theano variables and expressions\n",
    "X = T.tensor4('X', dtype='float32')\n",
    "Y = T.matrix('T')\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "b2 = theano.shared(b2_init, 'b2')\n",
    "W3 = theano.shared(W3_init.astype(np.float32), 'W3')\n",
    "b3 = theano.shared(b3_init, 'b3')\n",
    "W4 = theano.shared(W4_init.astype(np.float32), 'W4')\n",
    "b4 = theano.shared(b4_init, 'b4')\n",
    "\n",
    "# momentum changes\n",
    "dW1 = theano.shared(np.zeros(W1_init.shape, dtype=np.float32), 'dW1')\n",
    "db1 = theano.shared(np.zeros(b1_init.shape, dtype=np.float32), 'db1')\n",
    "dW2 = theano.shared(np.zeros(W2_init.shape, dtype=np.float32), 'dW2')\n",
    "db2 = theano.shared(np.zeros(b2_init.shape, dtype=np.float32), 'db2')\n",
    "dW3 = theano.shared(np.zeros(W3_init.shape, dtype=np.float32), 'dW3')\n",
    "db3 = theano.shared(np.zeros(b3_init.shape, dtype=np.float32), 'db3')\n",
    "dW4 = theano.shared(np.zeros(W4_init.shape, dtype=np.float32), 'dW4')\n",
    "db4 = theano.shared(np.zeros(b4_init.shape, dtype=np.float32), 'db4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward pass will include our two convpool layer, followed by our fully connected neural network layer, and finishing with the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "Z1 = convpool(X, W1, b1)\n",
    "Z2 = convpool(Z1, W2, b2)\n",
    "Z3 = relu(Z2.flatten(ndim=2).dot(W3) + b3)\n",
    "pY = T.nnet.softmax(Z3.dot(W4) + b4)\n",
    "\n",
    "# define the cost function and prediction\n",
    "params = (W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "reg_cost = reg*np.sum((param*param).sum() for param in params)\n",
    "cost = -(Y * T.log(pY)).sum() + reg_cost\n",
    "prediction = T.argmax(pY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define our update parameters, as well as the train and prediction functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 3: training expressions and functions\n",
    "update_W1 = W1 + mu*dW1 - lr*T.grad(cost, W1)\n",
    "update_b1 = b1 + mu*db1 - lr*T.grad(cost, b1)\n",
    "update_W2 = W2 + mu*dW2 - lr*T.grad(cost, W2)\n",
    "update_b2 = b2 + mu*db2 - lr*T.grad(cost, b2)\n",
    "update_W3 = W3 + mu*dW3 - lr*T.grad(cost, W3)\n",
    "update_b3 = b3 + mu*db3 - lr*T.grad(cost, b3)\n",
    "update_W4 = W4 + mu*dW4 - lr*T.grad(cost, W4)\n",
    "update_b4 = b4 + mu*db4 - lr*T.grad(cost, b4)\n",
    "\n",
    "# update weight changes\n",
    "update_dW1 = mu*dW1 - lr*T.grad(cost, W1)\n",
    "update_db1 = mu*db1 - lr*T.grad(cost, b1)\n",
    "update_dW2 = mu*dW2 - lr*T.grad(cost, W2)\n",
    "update_db2 = mu*db2 - lr*T.grad(cost, b2)\n",
    "update_dW3 = mu*dW3 - lr*T.grad(cost, W3)\n",
    "update_db3 = mu*db3 - lr*T.grad(cost, b3)\n",
    "update_dW4 = mu*dW4 - lr*T.grad(cost, W4)\n",
    "update_db4 = mu*db4 - lr*T.grad(cost, b4)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    updates=\n",
    "        [(W1, update_W1),\n",
    "        (b1, update_b1),\n",
    "        (W2, update_W2),\n",
    "        (b2, update_b2),\n",
    "        (W3, update_W3),\n",
    "        (b3, update_b3),\n",
    "        (W4, update_W4),\n",
    "        (b4, update_b4)]+\n",
    "        [(dW1, update_dW1),\n",
    "        (db1, update_db1),\n",
    "        (dW2, update_dW2),\n",
    "        (db2, update_db2),\n",
    "        (dW3, update_dW3),\n",
    "        (db3, update_db3),\n",
    "        (dW4, update_dW4),\n",
    "        (db4, update_db4)]\n",
    "    ,\n",
    ")\n",
    "\n",
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we do our batch gradient decent and iterate through our dataset for the predetermined number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 2353.433 / 0.883\n",
      "Cost / err at iteration i=2, j=0: 69.560 / 0.028\n",
      "Cost / err at iteration i=4, j=0: 56.687 / 0.017\n",
      "Cost / err at iteration i=6, j=0: 43.612 / 0.011\n",
      "Cost / err at iteration i=8, j=0: 39.772 / 0.013\n",
      "Cost / err at iteration i=10, j=0: 37.467 / 0.011\n",
      "Cost / err at iteration i=12, j=0: 42.521 / 0.014\n",
      "Cost / err at iteration i=14, j=0: 36.269 / 0.011\n",
      "Cost / err at iteration i=16, j=0: 41.879 / 0.012\n",
      "Cost / err at iteration i=18, j=0: 45.308 / 0.018\n",
      "Cost / err at iteration i=20, j=0: 38.035 / 0.012\n",
      "Cost / err at iteration i=22, j=0: 39.195 / 0.013\n",
      "Cost / err at iteration i=24, j=0: 40.340 / 0.011\n",
      "Cost / err at iteration i=26, j=0: 40.878 / 0.011\n",
      "Cost / err at iteration i=28, j=0: 42.515 / 0.013\n",
      "Cost / err at iteration i=29, j=0: 40.796 / 0.011\n",
      "Elapsed time: 0:17:31.629370\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgERkQamEBARaWD/H8MrOaXJ84HYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10774caef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "LL = []\n",
    "for i in range(max_iter):\n",
    "    Xtrain, Ytrain_ind = shuffle(Xtrain, Ytrain_ind)\n",
    "    for j in range(int(n_batches)):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            LL.append(cost_val)\n",
    "            if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err))\n",
    "                \n",
    "print(\"Elapsed time:\", (datetime.now() - t0))\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
