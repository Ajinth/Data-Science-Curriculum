{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Algorithm (SVM)\n",
    "\n",
    "## Model Summary\n",
    "\n",
    "Support Vector Machine is a supervised machine learning algorithm used for both classification and regression analysis. SVM allows for multi-class, linear, and non linear classification.\n",
    "\n",
    "A couple key terms:\n",
    " - Hyperplane: a substance (plane) of one dimension less than its ambient space. In a two-dimensional space, this would be a 'line' that separates the two classes.\n",
    " - Support vectors: observations nearest to the hyperplane.\n",
    " - Margin: the distance between the support vectors and the hyperplane.\n",
    " \n",
    "Succinctly stated, SVM seeks to construct a hyperplane that maximizes the margin between the support vectors. The larger the margin, the lower the generalization error (AKA the out-of-sample-error).\n",
    "\n",
    "![Title](extras/SVM.png)\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    " - Kernel: the kernel parameter allow us to adjust the linearity of our hyperplane. The default value is \"rbf,\" which is also used to perform the [kernel trick](https://github.com/inside-track/analytics/blob/master/Cheat_Sheets/The%20Kernel%20Trick.ipynb). \n",
    " - Gamma: this parameter is used to tune the _complexity_ of the kernels used in non-linear classification. The higher the gamma, the more isolated the classifcation areas will be.\n",
    " - C: the standard SVM first seeks a hyperplane that correctly classifies the observations _before_ maximizing the margin. This is known as the 'hard margin,' and it can result in poor models when there are outliers. The C parameter allows us to have a 'soft margin,' thereby ignoring the outliers in favor of a higher margin. A higher C means the cost of mislassification is high (resulting in low bias and high variance). A low C means the cost of misclassification is low (resulting in high bias and low variance).\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "Pros:\n",
    " - Work well in high-dimensional spaces.\n",
    " - Memory efficient, since it relies only on the support vectors in the decision function.\n",
    " - Versatile (works with non-linear functions using Kernels).\n",
    "\n",
    "Cons:\n",
    " - Predicting probabilities is very expensive as it requires using five-fold cross-validation.\n",
    " - Doesn't work well if the number of features is much greater than the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In this example, we will use the Bernoulli classification model to predict the Gender of an ASU PSC applicant using the Military and Ethnicity fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "os.chdir('C:\\\\Users\\\\zlatan.kremonic\\\\Dropbox\\\\Documents\\\\Analytics\\\\InsideTrack\\\\Analytics\\\\Cheat_Sheets\\\\data')\n",
    "import sys\n",
    "\n",
    "# set the python path\n",
    "sys.path.append('C:\\\\Users\\\\zlatan.kremonic\\\\Dropbox\\\\Documents\\\\Analytics\\\\InsideTrack\\\\Analytics')\n",
    "from oa import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data model evaluation\n",
      "\n",
      "[205, 98, 2257, 924]\n",
      "Accuracy: 0.706659012629\n",
      "Precision: 0.676567656766\n",
      "Recall: 0.181576616475\n",
      "Mean Actual: 0.324052812859\n",
      "\n",
      "Test data model evaluation\n",
      "\n",
      "[78, 43, 935, 386]\n",
      "Accuracy: 0.702496532594\n",
      "Precision: 0.644628099174\n",
      "Recall: 0.168103448276\n",
      "Mean Actual: 0.321775312067\n"
     ]
    }
   ],
   "source": [
    "# load the datafile\n",
    "asu_study = pd.read_csv('asu_data_NB.csv')\n",
    "\n",
    "# convert all columns to dummy variables\n",
    "asu_study = stats.dummy_vars(asu_study)\n",
    "\n",
    "# create our train and test data sets\n",
    "train, vald, test = stats.train_val_test(asu_study,.7)\n",
    "\n",
    "X_train = train.ix[:, 2:]\n",
    "Y_train = train.ix[:, 1]\n",
    "\n",
    "X_test = test.ix[:, 2:]\n",
    "Y_test = test.ix[:, 1]\n",
    "\n",
    "# run the BernoulliNB classifer using the training data set\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# generate predicted values and model evaluation using our training data set\n",
    "Y_pred = clf.predict(X_train)\n",
    "\n",
    "print 'Training data model evaluation\\n'\n",
    "confusion_matrix(Y_train, Y_pred)\n",
    "stats.confusion_matrix_summary(Y_train, Y_pred)\n",
    "\n",
    "# generate predicted values and model evaluation using our test data set\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print '\\nTest data model evaluation\\n'\n",
    "confusion_matrix(Y_test, Y_pred)\n",
    "stats.confusion_matrix_summary(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    " - http://scikit-learn.org/stable/modules/svm.html\n",
    " - http://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/\n",
    " - https://en.wikipedia.org/wiki/Support_vector_machine\n",
    " - https://www.quora.com/What-are-C-and-gamma-with-regards-to-a-support-vector-machine\n",
    "\n",
    "## Further Improvements\n",
    "\n",
    " - Create a more comprehensive example with a better dataset (use visuals, show the effects of each of the parameters).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
