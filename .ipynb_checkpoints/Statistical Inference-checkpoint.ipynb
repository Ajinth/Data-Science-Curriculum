{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference\n",
    "\n",
    "Statistical inference is the process of drawing conclusions about a population based on a sample of data through the use of mathematical deductive reasoning. The science behind properly collecting a representative sample is known as experimental design and is out of the scope of this module. \n",
    "\n",
    "### Estimating a Population Mean\n",
    "\n",
    "When doing statistical inference, it is important that we distinguish between the population parameters and the sample parameters. Our population has a center, described by the expected value of the random variable Y:\n",
    "\n",
    "![](extras/si1.png)\n",
    "\n",
    "The population variance is \n",
    "\n",
    "![](extras/si2.png)\n",
    "\n",
    "Our sample mean, in a sample of N observations is known as y-bar:\n",
    "\n",
    "![](extras/si3.png)\n",
    "\n",
    "The sampel mean is generalized to the estimator Y-bar:\n",
    "\n",
    "![](extras/si4.png)\n",
    "\n",
    "Y-bar will differ from sample to sample due to _sampling variation_. This variability is captured by the estimator's probability density function, also known as its sampling distribution. Regardless, our sample mean estimator is an unbiased estimator of the population mean, meaning if we took the mean of multiple samples, their average would equal the true population mean:\n",
    "\n",
    "![](extras/si5.png)\n",
    "\n",
    "The variance of our sample mean estimator is: \n",
    "\n",
    "![](extras/si6.png)\n",
    "\n",
    "The Central Limit Theorem says that the sample average of N independent random variables from any probability distribution will have an approximate standard normal distribution after standardizing (i.e. subtracting the mean and dividing by the standard deviation), if the sample is sufficiently large. \n",
    "\n",
    "![](extras/si7.png)\n",
    "\n",
    "The unbiased estimator of the population variance (sigma squared) is: \n",
    "\n",
    "![](extras/si8.png)\n",
    "\n",
    "Now we can obtain the variance of our our estimator Y-bar:\n",
    "\n",
    "![](extras/si9.png)\n",
    "\n",
    "And the standard error of the mean is:\n",
    "\n",
    "![](extras/si10.png)\n",
    "\n",
    "\n",
    "### Interval Estimation\n",
    "\n",
    "In the case where the true population variance is known and we can invoke the Central Limit Theorem, we can create a standard normal variable \n",
    "\n",
    "![](extras/si11.png)\n",
    "\n",
    "Using the cumulative distribution function of this standard normal variable, we can identify where in this distribution a given sample estimator is, thus allowing us to know the likelihood of observing a value greater or less that that observation. For example, the critical value z for which 95% of the values are contained within +/- z is: \n",
    "\n",
    "![](extras/si12.png)\n",
    "\n",
    "This can be illustrated here: \n",
    "\n",
    "![](extras/si13.png)\n",
    "\n",
    "We can now plug in our estimator equation in for Z and obtain: \n",
    "\n",
    "![](extras/si14.png)\n",
    "\n",
    ", which gives us our interval estimator as: \n",
    "\n",
    "![](extras/si15.png)\n",
    "\n",
    "In the case of an unknown population variance, the standardized random variable has a t-distribution with N-1 degrees of freedom: \n",
    "\n",
    "![](extras/si16.png)\n",
    "\n",
    "Now, our interval estimator can be arrived at as follows: \n",
    "\n",
    "![](extras/si17.png)\n",
    "\n",
    "Example: \n",
    "\n",
    "Given a random sample of size N=50, we estimated the mean U.S. hip width to be y-bar=17.158 inches. The estimated population variance is sigma-hat-squared=3.265; and thus the estimated standard deviation is sigma-hat=1.807. The standard error of the mean is 1.807/50^1/2 = 0.2556. The critical value for interval estimation comes from a t-distribution with N-1=49 degrees of freedom. The value for a 95% confidence interval = 2.009552, which can be rounded to 2.01. Thus, the 95% interval estimate is: \n",
    "\n",
    "![](extras/si26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Hypothesis testing procedures compare a conjecture, or a hypothesis, we have about a population to the information contained in a sample of data. The conjectures we test here concern the mean of a normal population. Hypothesis tests use sample information about a parameter, namely its point estimate and its standard error, to draw a conclusion about the hypothesis.\n",
    "\n",
    "The five components of a hypothesis test are: \n",
    "- A null hypothesis, Ho\n",
    "- An alternate hypothesis, H1\n",
    "- A test statistic\n",
    "- A rejection region\n",
    "- A conclusion \n",
    "\n",
    "For a null hypothesis Ho: μ = c, three possible alternative hypotheses are: \n",
    "- H1: μ > c\n",
    "- H1: μ < c\n",
    "- H1: μ ≠ c\n",
    "\n",
    "The sample information about the null hypothesis is embodied in the sample value of a test statistic, whose probability distribution is known when the null hypothesis is true.  If the null hypothesis is true, then \n",
    "\n",
    "![](extras/si18.png)\n",
    "\n",
    "A given _level of significance_, alpha, will allow us to obtain a test statistic that determines a rejection region(s). If a value of the test statistic is obtained that falls in a region of low probability, then it is unlikely that the null hypothesis is true. \n",
    "\n",
    "![](extras/si19.png)\n",
    "\n",
    "Similarly, each test statistic has an associated p-value, which tells us the probability of observing that test statistic (or greater) if the null hypothesis is true. \n",
    "\n",
    "![](extras/si20.png)\n",
    "\n",
    "#### Example\n",
    "\n",
    "![](extras/si27.png)\n",
    "\n",
    "![](extras/si28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Power of a Test\n",
    "\n",
    "Type I error occurs if the null hypothesis is rejected when it is true. We denote α=P(Type I Error). Type II error occurs if the null hypothesis is not rejected when it is false. We denote β= P(Type II Error).\n",
    "\n",
    "The power of a hypothesis test is the probability of making the correct decision if the alternative hypothesis is true. That is, the power of a hypothesis test is the probability of rejecting the null hypothesis when the alternative hypothesis is true.\n",
    "\n",
    "So we get,\n",
    "\n",
    "Power = 1−β = the probability of correctly rejecting a false null hypothesis.\n",
    "\n",
    "When the data indicate that one cannot reject the null hypothesis, there are two possible reasons for the failure of rejection of the null hypothesis:\n",
    "\n",
    "the null hypothesis is reasonable, or\n",
    "there's an insufficient sample size to achieve a powerful test.\n",
    "\n",
    "**Example**  \n",
    "Let X denote the height of a randomly Penn State students. Assume that X is normally distributed with unknown mean μ and standard deviation of 9. Take a random sample of n = 25 students, so that, after setting the probability of committing a Type I error at α=0.05, we can test the null hypothesis H0:μ=170 against the alternative hypothesis that HA:μ>170.\n",
    "\n",
    "What is the power of the hypothesis test if the true population mean were μ=175?\n",
    "\n",
    "![](extras/si21.png)\n",
    "\n",
    "So we should reject the null hypothesis when the observed sample mean is 172.961 or greater:\n",
    "\n",
    "We get\n",
    "\n",
    "![](extras/si22.png)\n",
    "\n",
    "and illustrated below:\n",
    "\n",
    "![](extras/si23.png)\n",
    "\n",
    "In summary, we have determined that we have a 97.93% chance of rejecting the null hypothesis H0:μ=170 in favor of the alternative hypothesis HA:μ>170 if the true unknown population mean is in reality μ=175.\n",
    "\n",
    "**Calculating Sample Size**  \n",
    "If the sample size is fixed, then decreasing Type I error α will increase Type II error β. If one wants both to decrease, then one has to increase the sample size.\n",
    "\n",
    "To calculate the smallest sample size needed for specified α, β, μa, then (μa is the likely value of μ at which you want to evaluate the power.\n",
    "\n",
    "One-Tailed test:\n",
    "\n",
    "![](extras/si24.png)\n",
    "\n",
    "Two-Tailed test:\n",
    "\n",
    "![](extras/si25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another rule of thumb for choosing a sample size is to use this equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ N = 16\\frac{\\sigma^2}{\\delta^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in means test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson explains how to conduct a hypothesis test for the difference between two means. The test procedure, called the two-sample t-test, is appropriate when the following conditions are met:\n",
    "\n",
    "- The sampling method for each sample is simple random sampling.\n",
    "- The samples are independent.\n",
    "- Each population is at least 20 times larger than its respective sample.\n",
    "- The sampling distribution is approximately normal, which is generally the case if any of the following conditions apply.  \n",
    "\n",
    "    - The population distribution is normal.\n",
    "    - The population data are symmetric, unimodal, without outliers, and the sample size is 15 or less.\n",
    "    - The population data are slightly skewed, unimodal, without outliers, and the sample size is 16 to 40.\n",
    "    - The sample size is greater than 40, without outliers.  \n",
    "\n",
    "This approach consists of four steps: (1) state the hypotheses, (2) formulate an analysis plan, (3) analyze sample data, and (4) interpret results.\n",
    "\n",
    "In the case of unequal varainces between our two samples, we use Welch's test. The standard error of our sampling distribution is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ SE = \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, s1 and s2 represent our sample standard deviations, which are calculated using (n-1) degrees of freedom.  \n",
    "\n",
    "The degrees of freedom associated with our test can be calculated using this formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\large df = \\frac{\\left[\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2} \\right]^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the associated t-statistic is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "t = \\frac{(\\bar x_1 - \\bar x_2 - d)}{SE}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, x1 and x2 are our sample means, while d is the hypothesized difference between the two population means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case where we have equal variances, the test statistic becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "t = \\frac{\\bar x_1 - \\bar x_2}{s_p\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where Sp is the pooled standard deviation, and it can be calculated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "s_p = \\sqrt{\\frac{(n_1-1)s_{x_1}^2+(n_2-1)s_{x_2}^2}{n_1+n_2-2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://onlinecourses.science.psu.edu/statprogram/review_of_basic_statistics\n",
    "- http://stattrek.com/hypothesis-test/difference-in-means.aspx?Tutorial=AP\n",
    "- Hill, R. C., Griffiths, W. E., & Lim, G. C., 2018. Principles of econometrics (3rd ed.). Hoboken, N.J.: Wiley"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
