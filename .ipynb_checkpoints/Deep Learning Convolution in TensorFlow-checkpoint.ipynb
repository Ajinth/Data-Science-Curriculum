{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module describes how a convolutional neural network works, and we will demonstrate its application on the MNIST dataset using TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) are a type of feed-forward artificial neural networks whose neuron interconnectivity emulates that of the animal visual cortex. CNNs are are particularly useful with computer vision tasks such as image classification; however, they can be applied in other machine learning tasks as long as the ordering of the attributes along at least one of the dimensions is essential for classification. For example, CNNs can also be used in natural language processing and sound analytics.  \n",
    "\n",
    "The primary components of CNNs are the convolutional layer, the pooling layer, the ReLU layer, and the fully connected layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer  \n",
    "\n",
    "The convolutional layer begins with a 3-dimensional version of the original input, generally an image with dimensions of color, width, and height. Then, the image is broken into a subset of filters, also known as kernels, each with a smaller receptive fields than the overall image. These filters are then convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.  \n",
    "\n",
    "The activation maps are then stacked to form the depth of the output of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.\n",
    "\n",
    "A key concept here is local connectivity, which indicates that each neuron is connected to only a small region of the input volume.  The size of the filter, also known as the receptive field, is a key factor in determining the extent of the connectivity.  \n",
    "\n",
    "Other key parameters are depth, stride, and padding. Depth indicates how many feature maps we are building. Stride controls the step of each filter as it moves across and down the image. Generally, a step of one is used, leading to heavily overlapped receptive fields and large output volumes. Padding allows us to control the spatial size of the output volume. If we add zero-padding, it will give us an output width and height that is the same size as the input volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer  \n",
    "\n",
    "Pooling is a form of non-linear down-sampling that allows us to shrink the output of convolution while keeping preserving the most prominent features. The most common method of pooling is max pooling, where the input image, in this case the activation map from the convolution layer, is partitioned into non-overlapping rectanges, from which the maximim value is taken.  \n",
    "\n",
    "One of the key advantages of pooling is that it reduces the number of parameters and the amount of computation in the network, thereby reducing overfitting. Additionally, because pooling takes away information about the exact location of a particular feature in favor of its position relative to other features, it in turn offers a form of translational invariance.  \n",
    "\n",
    "The most common pooling size is 2-by-2 with a stride of 2, thereby eliminating 75% of the activations from the input map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU layer  \n",
    "\n",
    "The Rectifier Linear Unit layer applies the activation function $f(x)= max(0,x)$ to the output of the pooling layer. It increases the nonlinear properties of the decision function and of the overall network without affecting the receptive fields of the convolution layer. Of course, we can also apply other standard non linear activation functions, such as tanh or the sigmoid function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer  \n",
    "\n",
    "Following the ReLU layer, we take its output and flatten it to vector that will serve to tune our weights in a standard neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with TensorFlow on the MNIST data set  \n",
    "\n",
    "Here, we will show how we can achieve almost 99% accuracy on the MNIST data set using CNN with TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic helper functions will give us the error rate and the indicator matrix for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data, normalize it, reshape it, and generate our train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 1: load the data, transform as needed\n",
    "data = pd.read_csv(os.path.join('Data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_data(data):\n",
    "    data = data.as_matrix().astype(np.float32)\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:]\n",
    "    mu = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    np.place(std, std == 0, 1)\n",
    "    X = (X - mu) / std # normalize the data\n",
    "    Y = data[:, 0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(len(X), 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our convpool function, we will take a stride of one, and we will ensure that the dimensions of output of the convolution are the same as the input by setting _padding_ to 'SAME.' Our downnsampling will be of size two, and we will apply the ReLu activation function on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convpool(X, W, b):\n",
    "    # just assume pool size is (2,2) because we need to augment it with 1s\n",
    "    # - stride is the interval at which to apply the convolution\n",
    "    conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_out = tf.nn.bias_add(conv_out, b)\n",
    "    pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return tf.nn.relu(pool_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we always initialize weights is random normal / sqrt(fan in + fan out). The key point is it's random with a variance restricted by the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_filter(shape, poolsz):\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[:-1]) + shape[-1]*np.prod(shape[:-2] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our gradient descent parameters, which include the number of iterations, batch size, number of hidden layers, number of classes, and the pool size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient descent params\n",
    "max_iter = 6\n",
    "print_period = 10\n",
    "N = Xtrain.shape[0]\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "\n",
    "# limit samples since input will always have to be same size\n",
    "# you could also just do N = N / batch_sz * batch_sz\n",
    "\n",
    "# initial weights\n",
    "M = 500\n",
    "K = 10\n",
    "poolsz = (2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When initializing our filters, we have to remember that TensorFlow has its own ordering of dimensions. The output after convpooling is going to be 7x7, which is different from Theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1_shape = (5, 5, 1, 20) # (filter_width, filter_height, num_color_channels, num_feature_maps)\n",
    "W1_init = init_filter(W1_shape, poolsz)\n",
    "b1_init = np.zeros(W1_shape[-1], dtype=np.float32) # one bias per output feature map\n",
    "\n",
    "W2_shape = (5, 5, 20, 50) # (filter_width, filter_height, old_num_feature_maps, num_feature_maps)\n",
    "W2_init = init_filter(W2_shape, poolsz)\n",
    "b2_init = np.zeros(W2_shape[-1], dtype=np.float32)\n",
    "\n",
    "W3_init = np.random.randn(W2_shape[-1]*7*7, M) / np.sqrt(W2_shape[-1]*7*7 + M)\n",
    "b3_init = np.zeros(M, dtype=np.float32)\n",
    "W4_init = np.random.randn(M, K) / np.sqrt(M + K)\n",
    "b4_init = np.zeros(K, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our input and target placeholders, as well as the variables which will be updated during the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define variables and expressions\n",
    "# using None as the first shape element takes up too much RAM unfortunately\n",
    "X = tf.placeholder(tf.float32, shape=(batch_sz, 28, 28, 1), name='X')\n",
    "T = tf.placeholder(tf.float32, shape=(batch_sz, K), name='T')\n",
    "W1 = tf.Variable(W1_init.astype(np.float32))\n",
    "b1 = tf.Variable(b1_init.astype(np.float32))\n",
    "W2 = tf.Variable(W2_init.astype(np.float32))\n",
    "b2 = tf.Variable(b2_init.astype(np.float32))\n",
    "W3 = tf.Variable(W3_init.astype(np.float32))\n",
    "b3 = tf.Variable(b3_init.astype(np.float32))\n",
    "W4 = tf.Variable(W4_init.astype(np.float32))\n",
    "b4 = tf.Variable(b4_init.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our feedforward mechanism. Note that flattening the output of our second convpool layer requires an extra step when using TensorFlow. We will also apply RMSProp in order to accelerate our process of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z1 = convpool(X, W1, b1)\n",
    "Z2 = convpool(Z1, W2, b2)\n",
    "Z2_shape = Z2.get_shape().as_list()\n",
    "Z2r = tf.reshape(Z2, [Z2_shape[0], np.prod(Z2_shape[1:])])\n",
    "Z3 = tf.nn.relu( tf.matmul(Z2r, W3) + b3 )\n",
    "Yish = tf.matmul(Z3, W4) + b4\n",
    "\n",
    "cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits = Yish, labels = T))\n",
    "\n",
    "train_op = tf.train.RMSPropOptimizer(0.0001, decay=0.99, momentum=0.9).minimize(cost)\n",
    "\n",
    "# we'll use this to calculate the error rate\n",
    "predict_op = tf.argmax(Yish, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training process is standard, except that when making predictions agains the test set, due to RAM limitations we need to have a fixed size input; so as a result, we have have to add a slightly complex total cost and prediction computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-65-81f1545b1f0a>:3: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Cost / err at iteration i=0, j=0: 2117.001 / 0.726\n",
      "Cost / err at iteration i=2, j=0: 41.186 / 0.010\n",
      "Cost / err at iteration i=4, j=0: 33.965 / 0.012\n",
      "Elapsed time: 0:10:03.469070\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b7c490ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "LL = []\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    for i in range(int(max_iter)):\n",
    "        for j in range(int(n_batches)):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "            if len(Xbatch) == batch_sz:\n",
    "                session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\n",
    "                if j % print_period == 0:\n",
    "                    test_cost = 0\n",
    "                    prediction = np.zeros(len(Xtest))\n",
    "                    for k in range(int(len(Xtest) / batch_sz)):\n",
    "                        Xtestbatch = Xtest[k*batch_sz:(k*batch_sz + batch_sz),]\n",
    "                        Ytestbatch = Ytest_ind[k*batch_sz:(k*batch_sz + batch_sz),]\n",
    "                        test_cost += session.run(cost, feed_dict={X: Xtestbatch, T: Ytestbatch})\n",
    "                        prediction[k*batch_sz:(k*batch_sz + batch_sz)] = session.run(\n",
    "                            predict_op, feed_dict={X: Xtestbatch})\n",
    "                    err = error_rate(prediction, Ytest)\n",
    "                    if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                        print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, test_cost, err))\n",
    "                    LL.append(test_cost)\n",
    "print(\"Elapsed time:\", (datetime.now() - t0))\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion  \n",
    "\n",
    "As we"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References  \n",
    " - https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
    " - http://deeplearning.net/tutorial/lenet.html\n",
    " - https://www.udemy.com/deep-learning-convolutional-neural-networks-theano-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
