{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When it comes to deep learning, Theano is one of the essential libraries for efficient optimization of neural networks. In this write up, we tackle the standard MNIST data set using Theano, and we explore the implementation of a couple key techniques in neural network optimization: momentum and RMSProp. \n",
    "\n",
    "Our primary goal is to illustrate the basics of Theano and how it can be used to arrive at a good solution for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The dataset and our problem  \n",
    "\n",
    "The MNIST data set is composed of gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Thus, the data set has 785 columns, where the first column is the label, while the rest of the columns contain the pixel-values of the associated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('Data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f511b78dcc0>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5128e2d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.asarray(data.iloc[6, 1:]).reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define helper functions\n",
    "\n",
    "The first function simply tells us our error rate, which is the proportion of misclassified observations when compared to the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we normalize our data by subtracting the mean from each observation and dividing by the standard deviation. This will accelarate our convergence toward an optimal solutions as well as improve the accuracy of our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_data(data):\n",
    "    data = data.as_matrix().astype(np.float32)\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:]\n",
    "    mu = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    np.place(std, std == 0, 1)\n",
    "    X = (X - mu) / std # normalize the data\n",
    "    Y = data[:, 0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also create an indicator matrix to allow us to predict the probability of each class for a given observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 1: get the data and define our key variables  \n",
    "\n",
    "First, we pull in the normalized data and define the number of training iterations (epochs). We also choose our learning rate and regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data(data)\n",
    "\n",
    "max_iter = 30\n",
    "print_period = 10\n",
    "\n",
    "lr = 0.00004\n",
    "reg = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we create a our train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are doing only a single-layer neural network, and thus we need to define the dimensions of our input matrix (NxD), the weights of our hidden layer (DxM), and the hidden-layer-to-output weights (MxK). Our model will also have bias terms on either end of the hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "M = 300\n",
    "K = 10\n",
    "W1_init = np.random.randn(D, M) / 28\n",
    "b1_init = np.zeros(M)\n",
    "W2_init = np.random.randn(M, K) / np.sqrt(M)\n",
    "b2_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2: define Theano variables and expressions  \n",
    "\n",
    "First let's define our necessary variables, which are the matrices for our inputs and our targets. We also define our Theano shared variables, which can and will be updated through our training iterations. The hidden layer output matrix as well as our final output matrix are composed of expressions. We will use the rectifier linear unit (ReLU) activation function on the hidden layer, and the standard softmax function for the output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "thX = T.matrix('X')\n",
    "\n",
    "# targets\n",
    "thT = T.matrix('T')\n",
    "\n",
    "# input-to-hidden-layer weights and bias\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "\n",
    "# hidden-layer-to-output weights and bias\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "b2 = theano.shared(b2_init, 'b2')\n",
    "\n",
    "# we can use the built-in theano functions to do relu and softmax\n",
    "thZ = T.nnet.relu( thX.dot(W1) + b1 )\n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The cost function takes into account regularization (we will use L2 regularization). The prediction function simply picks the class with the highest predicted probability for each given observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the cost function and prediction (theano automatically does the differentiation)\n",
    "cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2).sum())\n",
    "prediction = T.argmax(thY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 3: define training expressions and functions  \n",
    "\n",
    "During the training process, we will be updating our shared variables (input weights, output weights, and biases). These will be updated using standard gradient descent along our defined cost function.\n",
    "\n",
    "We define a theano function that takes our inputs and updates the shared variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "update_W1 = W1 - lr*T.grad(cost, W1)\n",
    "update_b1 = b1 - lr*T.grad(cost, b1)\n",
    "update_W2 = W2 - lr*T.grad(cost, W2)\n",
    "update_b2 = b2 - lr*T.grad(cost, b2)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)],outputs=[cost, prediction]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Additionally, during the training process, we will keep track of our cost and prediction so that we can evaluate our training and final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 4: training the model  \n",
    "\n",
    "Lastly, we perform our training procedure using batch gradient descent. Every tenth iteration, we collect the total cost and the error rate of our model. Looking at the plot of our cost over time, we can see that the cost was still decreasing ever so slightly, meaning that we could have possibly gotten a lower error rate if we increased the number of training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 2410.470 / 0.907\n",
      "Cost / err at iteration i=2, j=0: 496.179 / 0.126\n",
      "Cost / err at iteration i=4, j=0: 356.259 / 0.090\n",
      "Cost / err at iteration i=6, j=0: 302.546 / 0.083\n",
      "Cost / err at iteration i=8, j=0: 271.633 / 0.074\n",
      "Cost / err at iteration i=10, j=0: 249.965 / 0.068\n",
      "Cost / err at iteration i=12, j=0: 233.433 / 0.062\n",
      "Cost / err at iteration i=14, j=0: 221.366 / 0.058\n",
      "Cost / err at iteration i=16, j=0: 209.731 / 0.054\n",
      "Cost / err at iteration i=18, j=0: 200.541 / 0.052\n",
      "Cost / err at iteration i=20, j=0: 193.059 / 0.052\n",
      "Cost / err at iteration i=22, j=0: 186.630 / 0.051\n",
      "Cost / err at iteration i=24, j=0: 181.102 / 0.049\n",
      "Cost / err at iteration i=26, j=0: 175.427 / 0.047\n",
      "Cost / err at iteration i=28, j=0: 170.740 / 0.047\n",
      "Cost / err at iteration i=29, j=0: 168.542 / 0.047\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG9VJREFUeJzt3WtsXOed3/Hvf+4kRYmkRN0o2ZQT2amsbmSbUZ2NmmY3\nm/WlKOQgQCpvG2sLb7xAvI7TbVHYmxebbmsgXTTZXW8bF84mtbxIIjhwUqsb24DjOMg2ji9UrFg3\ny5ItyZJMidSVpEQO5/LvizlDjegZUhIvQ57z+wAHc+Y558w8Dw7AH5/nOWeOuTsiIhJNsXpXQERE\n6kchICISYQoBEZEIUwiIiESYQkBEJMIUAiIiEaYQEBGJMIWAiEiETRgCZrbSzF4ysz1mttvMHgzK\nv2Zmx8xsR7DcWXHMw2Z2wMz2mdltFeW3mNnOYNujZmbT0ywREbkcNtEdw2a2DFjm7r82s2ZgO3AX\n8Hlg0N3/+5j91wA/ANYDy4GfAte7e8HMXgO+DLwKPAs86u7Pjff9ixYt8s7Ozqtpm4hIZG3fvv2k\nu7dPtF9ioh3cvQfoCdYHzGwv0DHOIRuBre6eBQ6a2QFgvZkdAua7+ysAZvYkpTAZNwQ6Ozvp7u6e\nqJoiIlLBzA5fzn5XNCdgZp3ATZT+kwd4wMzeNLPvmllrUNYBHKk47GhQ1hGsjy2v9j33mVm3mXX3\n9fVdSRVFROQKXHYImNk84GngK+7eDzwGXAeso9RT+MZUVcrdH3f3Lnfvam+fsDcjIiJX6bJCwMyS\nlALge+7+IwB3P+HuBXcvAt+mNAcAcAxYWXH4iqDsWLA+tlxEROrkcq4OMuA7wF53/2ZF+bKK3T4L\n7ArWtwGbzCxtZquA1cBrwdxCv5ndGnzmPcAzU9QOERG5ChNODAOfAL4A7DSzHUHZnwF3m9k6wIFD\nwB8DuPtuM3sK2APkgfvdvRAc9yXgCaCB0oTwuJPCIiIyvSa8RLTeurq6XFcHiYhcGTPb7u5dE+2n\nO4ZFRCIstCHwxC8Psu0379e7GiIis1poQ+D7r73Hs2/21LsaIiKzWmhDIBmPkS8W610NEZFZLdQh\nMFKY3ZPeIiL1FuIQMHJ59QRERMYT4hCIkSsoBERExhPuEChqOEhEZDzhDgENB4mIjCu0IZBKmIaD\nREQmENoQSMQ0JyAiMpHQhkBpYlhzAiIi4wltCGg4SERkYqENAV0iKiIysdCGQGlOQMNBIiLjCW0I\nJBPGiHoCIiLjCm0IpOIx8goBEZFxhTYEkvEYRYeC7hoWEakp1CEAaHJYRGQcIQ4BA9C8gIjIOEIc\nAkFPQL8fJCJSU+hDIK85ARGRmkIcAsFwkHoCIiI1hTgENDEsIjKRCISAhoNERGoJcQiUhoPUExAR\nqS28IZDQcJCIyERCGwIpDQeJiEwotCGQiGk4SERkIqENgfJwkO4YFhGpLbQhUB4Oyms4SESkptCG\ngO4TEBGZWGhDIKFLREVEJhTaECgPB+lnI0REagttCOiOYRGRiU0YAma20sxeMrM9ZrbbzB4MytvM\n7AUz2x+8tlYc87CZHTCzfWZ2W0X5LWa2M9j2qJnZ9DTr4h3D+aJ6AiIitVxOTyAP/Ad3XwPcCtxv\nZmuAh4AX3X018GLwnmDbJuBG4HbgW2YWDz7rMeCLwOpguX0K23KJ0UtENRwkIlLThCHg7j3u/utg\nfQDYC3QAG4EtwW5bgLuC9Y3AVnfPuvtB4ACw3syWAfPd/RV3d+DJimOmXDKm4SARkYlc0ZyAmXUC\nNwGvAkvcvSfYdBxYEqx3AEcqDjsalHUE62PLq33PfWbWbWbdfX19V1LFUfoBORGRiV12CJjZPOBp\n4Cvu3l+5LfjPfsr+5Xb3x929y9272tvbr+oz4jHDDPIKARGRmi4rBMwsSSkAvufuPwqKTwRDPASv\nvUH5MWBlxeErgrJjwfrY8mlhZiTjMUY0HCQiUtPlXB1kwHeAve7+zYpN24DNwfpm4JmK8k1mljaz\nVZQmgF8Lho76zezW4DPvqThmWqTiMQ0HiYiMI3EZ+3wC+AKw08x2BGV/BnwdeMrM7gUOA58HcPfd\nZvYUsIfSlUX3u3shOO5LwBNAA/BcsEybRNwUAiIi45gwBNz9/wG1ruf/dI1jHgEeqVLeDay9kgpO\nRlI9ARGRcYX2jmEoDwdpTkBEpJZQh0BSw0EiIuMKdQgkNBwkIjKuUIdAMh5jJK/hIBGRWkIdAqm4\n6QfkRETGEeoQ0NVBIiLjC38IaDhIRKSmUIdAIm6MqCcgIlJTqEMgFY/peQIiIuMIdQhkknGG84WJ\ndxQRiajQh0A2p56AiEgtIQ+BGMM59QRERGoJeQjEFQIiIuMIdQg0JOMM5QqUHnwmIiJjhToEMskY\nRdfD5kVEagl5CMQBdIWQiEgNoQ6BdDkENC8gIlJVqEOgIQgBXSYqIlJdqEMgkyw1b0g9ARGRqsId\nAgkNB4mIjCfcITA6J6DhIBGRakIdAg2pUvPUExARqS7UIZAOhoM0JyAiUl2oQyCjS0RFRMYV8hAo\nNU+XiIqIVBfqEGjQHcMiIuMKdQiUh4OGRhQCIiLVRCIEdImoiEh1oQ6BeMxIxk3DQSIiNYQ6BEAP\nlhERGU9EQkDDQSIi1UQgBPScYRGRWsIfAgkNB4mI1BL6EGhIKQRERGoJfQiUegKaExARqWbCEDCz\n75pZr5ntqij7mpkdM7MdwXJnxbaHzeyAme0zs9sqym8xs53BtkfNzKa+OR+UTsb0A3IiIjVcTk/g\nCeD2KuV/5e7rguVZADNbA2wCbgyO+ZaZxYP9HwO+CKwOlmqfOeV0iaiISG0ThoC7/wI4fZmftxHY\n6u5Zdz8IHADWm9kyYL67v+LuDjwJ3HW1lb4SDck42byGg0REqpnMnMADZvZmMFzUGpR1AEcq9jka\nlHUE62PLqzKz+8ys28y6+/r6JlFFXSIqIjKeqw2Bx4DrgHVAD/CNKasR4O6Pu3uXu3e1t7dP6rMy\nybjmBEREariqEHD3E+5ecPci8G1gfbDpGLCyYtcVQdmxYH1s+bRrSie4kFUIiIhUc1UhEIzxl30W\nKF85tA3YZGZpM1tFaQL4NXfvAfrN7NbgqqB7gGcmUe/LNi+dYKRQJKsfkRMR+YDERDuY2Q+ATwGL\nzOwo8OfAp8xsHeDAIeCPAdx9t5k9BewB8sD97l7+6/slSlcaNQDPBcu0a86Umjg4nCc9Lz7B3iIi\n0TJhCLj73VWKvzPO/o8Aj1Qp7wbWXlHtpsC8dBAC2TwL56Vn+utFRGa10N8xXA6BgeF8nWsiIjL7\nhD8EMhd7AiIicqnQh0BzOgmU5gRERORSoQ8B9QRERGoLfwiU5wQUAiIiHxCZENBwkIjIB4U+BDLJ\nGPGYMZjN1bsqIiKzTuhDwMyYl06oJyAiUkXoQwBKQ0KaExAR+aBIhEBzRj0BEZFqIhEC89IJXSIq\nIlJFNEIgoxAQEakmGiGgiWERkaoiEQLNGU0Mi4hUE4kQUE9ARKS6iIRAkqFcgXyhWO+qiIjMKtEI\ngYyeKSAiUk0kQqCtqfRz0mcujNS5JiIis0skQqC1MQUoBERExopECLQ1lULg9Hn9iJyISKVIhMBo\nT+C8egIiIpUiEQKjPQENB4mIXCISIdCYipNKxNQTEBEZIxIhYGa0NaY4rRAQEblEJEIAoLUppauD\nRETGiEwItDUl1RMQERkjMiHQ2pjizAVdIioiUikyIdDWpDkBEZGxIhMCrY0pzg3l9CNyIiIVIhMC\n5XsFzg5pSEhEpCxyIaAhIRGRiyITAu3NaQB6+7N1romIyOwRmRBYOj8DwPH+4TrXRERk9ohOCCwI\nQuDcUJ1rIiIye0QmBDLJOK2NSXrOqScgIlI2YQiY2XfNrNfMdlWUtZnZC2a2P3htrdj2sJkdMLN9\nZnZbRfktZrYz2PaomdnUN2d8S+ZnOKHhIBGRUZfTE3gCuH1M2UPAi+6+GngxeI+ZrQE2ATcGx3zL\nzOLBMY8BXwRWB8vYz5x2yxZk1BMQEakwYQi4+y+A02OKNwJbgvUtwF0V5VvdPevuB4EDwHozWwbM\nd/dX3N2BJyuOmTFLFzRwXCEgIjLqaucElrh7T7B+HFgSrHcARyr2OxqUdQTrY8tn1NL5GU6dHyGb\nL8z0V4uIzEqTnhgO/rP3KajLKDO7z8y6zay7r69vyj53WXCFkO4VEBEpudoQOBEM8RC89gblx4CV\nFfutCMqOBetjy6ty98fdvcvdu9rb26+yih80epmoJodFRICrD4FtwOZgfTPwTEX5JjNLm9kqShPA\nrwVDR/1mdmtwVdA9FcfMmOUtpRB4/6zuFRARAUhMtIOZ/QD4FLDIzI4Cfw58HXjKzO4FDgOfB3D3\n3Wb2FLAHyAP3u3t5AP5LlK40agCeC5YZtaK1EYDDpy7M9FeLiMxKE4aAu99dY9Ona+z/CPBIlfJu\nYO0V1W6KZZJxli3IcOjU+XpWQ0Rk1ojMHcNl17Q1qicgIhKIXAh0LmxSCIiIBCIXAtcsbOTkYJbB\nbL7eVRERqbvIhUDnwiYA3lNvQEQkeiFw7cLyFUKaHBYRiWwIvHtSISAiErkQaM4kWbYgw4HewXpX\nRUSk7iIXAgCrlzTz9omBeldDRKTuIhkCNyyZx4HeQQrFKf3dOxGROSeSIbB6STPZfJH3TusKIRGJ\ntkiGwA1LmgHYd1xDQiISbZEMgQ8vngfAfs0LiEjERTIEmtIJOhc2suv9c/WuiohIXUUyBADWrWzh\njffOUnowmohINEU2BG66ppXegSw9evC8iERYhEOgBYA33jtb55qIiNRPZEPgI0vnk07E+PV7Z+pd\nFRGRuolsCKQSMW69biFP/uoQP+w+Uu/qiIjURWRDAOBvNq1j3coW/uL/7iFfKNa7OiIiMy7SIdDS\nmOILH+9kIJtn5zFdLioi0RPpEAD47Q8tBODld07VuSYiIjMv8iGwaF6ajyxt5pcHTta7KiIiMy7y\nIQCw4cOL6D58Rs8dFpHIUQgAn1mzhJF8kZ+91VvvqoiIzCiFANDV2UZ7c5pn3+ypd1VERGaUQgCI\nx4w71i7lpX29DAzn6l0dEZEZoxAIfPamDrL5Iv/njWP1roqIyIxRCATWrWzht1YsYMuvDuuXRUUk\nMhQCATNj88c7OdA7qHsGRCQyFAIV/uVvLaOtKcUTLx+qd1VERGaEQqBCJhnn7vUreXHvCY7oIfQi\nEgEKgTH+zT+7lnjM+Nuf7a93VUREpp1CYIzlLQ384W938sPtR9mlH5UTkZBTCFTxJ7+7mtbGFP/l\nH/boSiERCTWFQBULGpL8+89cz6sHT/P8ruP1ro6IyLSZVAiY2SEz22lmO8ysOyhrM7MXzGx/8Npa\nsf/DZnbAzPaZ2W2Trfx0uvtjK7lhSTP/9Sd7GRop1Ls6IiLTYip6Ar/j7uvcvSt4/xDworuvBl4M\n3mNma4BNwI3A7cC3zCw+Bd8/LRLxGP95440cOzvE/3hJk8QiEk7TMRy0EdgSrG8B7qoo3+ruWXc/\nCBwA1k/D90+ZW69byOduXsFjP3+Hl/W8AREJocmGgAM/NbPtZnZfULbE3cs/x3kcWBKsdwCVT3Q/\nGpTNan+x8UZWLWriD/7uVT732MucGszWu0oiIlNmsiGwwd3XAXcA95vZJys3eunSmiu+vMbM7jOz\nbjPr7uvrm2QVJ6cpneB7f3Qrf/qZ69l17Bx/9GQ3wznNEYhIOEwqBNz9WPDaC/yY0vDOCTNbBhC8\nlp/UcgxYWXH4iqCs2uc+7u5d7t7V3t4+mSpOiaULMnz506v563+9jh1HzvKVrTsoFHXpqIjMfVcd\nAmbWZGbN5XXg94FdwDZgc7DbZuCZYH0bsMnM0ma2ClgNvHa1318Pd/zTZXz1zn/C87uP8+DWN8jm\n1SMQkbktMYljlwA/NrPy53zf3Z83s9eBp8zsXuAw8HkAd99tZk8Be4A8cL+7z7m/ovduWEW+6Hz9\nubc4c2GE//Vvb6E5k6x3tURErorN9jtiu7q6vLu7u97V+ICntx/lPz39JqsXz+Pb93Sxsq2x3lUS\nERllZtsrLt2vSXcMX6XP3bKCLf9uPe+fHeKOv/lHtr72nn5iQkTmHIXAJGxYvYiffPmfs7ZjPg/9\naCeb//fr9Jwbqne1REQum4aDpkCx6Pz9K4f5+nNvMVIocm1bI3/4iU42fewaUgnlrIjMvMsdDlII\nTKHDp87zw+6jvHrwFK8fOsM1bY386Weu5199dDnxmNW7eiISIQqBOnJ3fv52H3/5/D729vSzevE8\nHvy91dy5dhkxhYGIzABNDNeRmfE7NyzmJw9s4H/+wc048Cfff4Pb/voX/PiNo1wYyde7iiIigHoC\nM6JQdH6ys4e/fXE/+3sHySRj/Ivr2+lc2MT6VW1sWL2IdGLW/qCqiMxBGg6ahYpF59WDp3l2Zw8/\nf7uXE+eyjBSKzEsn+N2PLOa2G5fyqRvaaUpP5h4+EZHLDwH9tZlBsZjx8Q8t5OMfWghANl/g5XdO\n8fzO47yw9wTbfvM+ybhx8zWtfPL6djZ8eBFrOxZoUllEpo16ArNEvlCk+/AZXnqrl3/cf5I9Pf1A\n6VGXS+dnWLWoiY+tauNjna2sWTafRFzTOSJSm4aD5riTg1l+eeAkr7x7ipODI7x1vJ8jp0s3ojWm\n4tx0TQtrOxZw4/IF3Lh8Pp0Lm9RjEJFRCoEQOn5umNcPnab70Gm2v3eGt48PMlIoAtCQjLO8JcOK\n1kbWdsxn7fIFrO1YQEdLgy5LFYkghUAEjOSL7O8dYG/PAHve7+d4/xAHT15g/4kB8sHzDhqScT60\nuIlr2hpZvqCB5S0NtDWlaEonuK69iWvbGjW0JBJCmhiOgFQiFgwHLYBbLpYP5wrsOz7A7vf72d87\nwIHeQd46PsDP3uplOFe85DOScWNlayOdi5roXNhER2sDyxZkWN5Sem1MxZmXThD8ZLiIhIxCIIQy\nyTgfXdnCR1e2XFLu7py5kOPcUI4zF0Z4t+887/QNcujkeQ6ePM+v3jnFUJVHZzanE3S0NrB4fob2\neWkWz0/TPi9Ne3NpWRy8KixE5h6FQISYGW1NKdqaUqyiiZuvab1kezkkjp8b5tjZIU70D3NhJM/7\nZ4c5euYCfQNZ9p8YoG8gOzrcVCmTjAWhkKkaEovmpZnfkKQpHWd+JkkmqRvkROpNISCjKkNizfL5\nNfcrFp1zQzl6B7L0DWTpGxymbyBLb3+WvsFS2YG+QX717inODeVqfk46EaOlMUlLQ4oFDUkWNCZp\naUjS0pgM3qdoaSitj+7XmKQ5ndBkt8gUUQjIFYvFjNamFK1NKW5Y2jzuvtl8oRQUwTKYzXM+m6d/\nOM+5oRxnL4wErzmOnL7ArmC92rDU6PcbzG9IjgZEOSxGw6MhSUtjqiI8kjRnkjSk4jQk4/p5b5EK\nCgGZVulEnBWtjaxovbLHbw7nCvQPleYvzgbBUBka5eA4G6y/d+o8Z4dy9A/lqDJSdYlk3GhIxmlK\nJ2hMxWlMlV4vvi+VNaUrtqUSNKYrtqUSNKTil+yT1FVWMgcpBGRWyiTjZJJxFs/PXNFxxaIzkM1z\nrhwaQyOcvZBjYDjPcK7AhZE8F0YKwZLn/EiBC9lSWd9AlvMjeS5kL24rTJQoFVLxGI3pIDDGhElD\nKkHTJe8r90uMHpdJxkjGS0vl52WSMU26y7RQCEioxGI2OiQ0We7OSKHI0EhhNCzOB+FxIVsoBUY5\nUCq3lQMmCJOeczkujBQ4n7247QqypdQuY7Q3Uvla7r2U15MJI2ZGzCBmRjxW6vU0phM0JkvBlEnG\nSSdipIIlnYgHr5VlpRBS8ISfQkCkBjMjnYiTTsRpubLRrHG5O9l8sSIUCqM9kOFcgXyxyEjByeYK\nDOUKo2EymL00fM5n8/QODI+Wnc8WyBWKuEPRPVgmV9dUIkY6HrskJMqhcWlZjFQiTioeI52MkYwZ\niXiMRNxKZcFx6WRpPRmPEY8ZiViMZNxGe37JuJU+O34xkOIxwzAsCLaYMVoP/VTK5CkERGaY2cU/\negun+buKRWcoV7ikd5LNF8jmi4wESzZfZKRQIJsrMlK4WFZaCpfuN7peYKRQJJsrMpjNX7I9my+Q\nKzj5QpFc0UeDaTokYlYKmKB3Uxk2yXiMRMyC4bVSKCXjFpSXy0pBVAqki+/L+5ePT8SNZKz0mohf\nGnLl8mRwbGL0Oy4eW+0zZ0uAKQREQiwWM5rSieAZFem61MHdyRdLvZ/hXCmA8oUiuYJTKHopWAoF\nhitCqLzkgiDBHQfcSw9pyhWKl3zecC4IqyCYykGUKxQZyhXoHy6Ovi9/d65QpFAs1a38meX1mWDG\nxWCpERj/8MCGab+fRiEgItPKzEb/A583Bx6YVAyCIV8sjvZo8uWQKFSWO7liUBaEVTlg8kF5OVgq\ny8vH1vr80c8sFknMQG9h9p8REZEZFIsZqZiRisgj2KPRShERqUohICISYQoBEZEIUwiIiESYQkBE\nJMIUAiIiEaYQEBGJMIWAiEiEmU/Xj3pMETPrAw5f5eGLgJNTWJ3ZJuztA7UxDMLePpidbbzW3dsn\n2mnWh8BkmFm3u3fVux7TJeztA7UxDMLePpjbbdRwkIhIhCkEREQiLOwh8Hi9KzDNwt4+UBvDIOzt\ngzncxlDPCYiIyPjC3hMQEZFxhDIEzOx2M9tnZgfM7KF612eqmNkhM9tpZjvMrDsoazOzF8xsf/Da\nWu96Xgkz+66Z9ZrZroqymm0ys4eD87rPzG6rT60vX432fc3MjgXncYeZ3Vmxba61b6WZvWRme8xs\nt5k9GJSH6RzWamM4zqO7h2oB4sA7wHVACvgNsKbe9Zqith0CFo0p+0vgoWD9IeC/1bueV9imTwI3\nA7smahOwJjifaWBVcJ7j9W7DVbTva8B/rLLvXGzfMuDmYL0ZeDtoR5jOYa02huI8hrEnsB444O7v\nuvsIsBXYWOc6TaeNwJZgfQtwVx3rcsXc/RfA6THFtdq0Edjq7ll3PwgcoHS+Z60a7atlLravx91/\nHawPAHuBDsJ1Dmu1sZY51cYwhkAHcKTi/VHGP2FziQM/NbPtZnZfULbE3XuC9ePAkvpUbUrValOY\nzu0DZvZmMFxUHiqZ0+0zs07gJuBVQnoOx7QRQnAewxgCYbbB3dcBdwD3m9knKzd6qS8aqsu9wtgm\n4DFKw5XrgB7gG/WtzuSZ2TzgaeAr7t5fuS0s57BKG0NxHsMYAseAlRXvVwRlc567Hwtee4EfU+pi\nnjCzZQDBa2/9ajhlarUpFOfW3U+4e8Hdi8C3uThUMCfbZ2ZJSn8cv+fuPwqKQ3UOq7UxLOcxjCHw\nOrDazFaZWQrYBGyrc50mzcyazKy5vA78PrCLUts2B7ttBp6pTw2nVK02bQM2mVnazFYBq4HX6lC/\nSSn/cQx8ltJ5hDnYPjMz4DvAXnf/ZsWm0JzDWm0MzXms98z0dCzAnZRm8N8Bvlrv+kxRm66jdMXB\nb4Dd5XYBC4EXgf3AT4G2etf1Ctv1A0pd6RylsdN7x2sT8NXgvO4D7qh3/a+yfX8P7ATepPQHY9kc\nbt8GSkM9bwI7guXOkJ3DWm0MxXnUHcMiIhEWxuEgERG5TAoBEZEIUwiIiESYQkBEJMIUAiIiEaYQ\nEBGJMIWAiEiEKQRERCLs/wMVOl1pyU/8ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5128bcfcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LL = []\n",
    "for i in range(max_iter):\n",
    "    Xtrain, Ytrain_ind = shuffle(Xtrain, Ytrain_ind)\n",
    "    for j in range(int(n_batches)):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            LL.append(cost_val)\n",
    "            if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err))\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## With Momentum  \n",
    "\n",
    "In gradient descent, [momentum](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum) speeds up the convergence towards the minimum of the cost function by taking into account the previous weight change.\n",
    "\n",
    "We can define velocity of the previous weight change as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\\begin{align}\n",
    "\\ v(t-1) = \\triangle w(t-1)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can update the weights as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\\begin{align}\n",
    "\\triangle w(t) = \\mu v(t-1) - \\eta \\bigtriangledown J(t)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In pseudo-code form:  \n",
    "`v = dw  \n",
    "dw = (momentum)*v - (learning rate)*(cost gradient)  \n",
    "w += dw`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 1: get the data and define our key variables  \n",
    "\n",
    "In order to incorporate momentum into our model, we need to first define our momentum rate 'mu,' which we will initially set as 0.9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data(data)\n",
    "\n",
    "max_iter = 30\n",
    "print_period = 10\n",
    "\n",
    "lr = 0.00004\n",
    "reg = 0.01\n",
    "mu = 0.9\n",
    "\n",
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "\n",
    "M = 300\n",
    "K = 10\n",
    "W1_init = np.random.randn(D, M) / 28\n",
    "dW1_init = np.zeros((D, M))\n",
    "b1_init = np.zeros(M)\n",
    "db1_init = np.zeros(M)\n",
    "W2_init = np.random.randn(M, K) / np.sqrt(M)\n",
    "dW2_init = np.zeros((M, K))\n",
    "b2_init = np.zeros(K)\n",
    "db2_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2: define theano variables and expressions  \n",
    "\n",
    "Next, we need to create variables that keep track of the change in our parameters. Above, we created matrices of zeroes with which we will initialize our new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "thX = T.matrix('X')\n",
    "\n",
    "# targets\n",
    "thT = T.matrix('T')\n",
    "\n",
    "# input-to-hidden-layer weights and bias\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "dW1 = theano.shared(dW1_init, 'dW1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "db1 = theano.shared(db1_init, 'db1')\n",
    "\n",
    "# hidden-layer-to-output weights and bias\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "dW2 = theano.shared(dW2_init, 'dW2')\n",
    "b2 = theano.shared(b2_init, 'b2')\n",
    "db2 = theano.shared(db2_init, 'db2')\n",
    "\n",
    "# we can use the built-in theano functions to do relu and softmax\n",
    "thZ = T.nnet.relu( thX.dot(W1) + b1 ) # relu is new in version 0.7.1 but just in case you don't have it\n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n",
    "\n",
    "# define the cost function and prediction (theano automatically does the differentiation)\n",
    "cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2).sum())\n",
    "prediction = T.argmax(thY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 3: define training expressions and functions  \n",
    "\n",
    "The new shared variables (our deltas) will be updated through each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# updates\n",
    "update_dW2 = mu*dW2 - lr*T.grad(cost, W2)\n",
    "\n",
    "update_W2 = W2 + mu*dW2 - lr*T.grad(cost, W2)\n",
    "\n",
    "update_db2 = mu*db2 - lr*T.grad(cost, b2)\n",
    "\n",
    "update_b2 = b2 + mu*db2 - lr*T.grad(cost, b2)\n",
    "\n",
    "update_dW1 = mu*dW1 - lr*T.grad(cost, W1)\n",
    "\n",
    "update_W1 = W1 + mu*dW1 - lr*T.grad(cost, W1)\n",
    "\n",
    "update_db1 = mu*db1 - lr*T.grad(cost, b1)\n",
    "\n",
    "update_b1 = b1 + mu*db1 - lr*T.grad(cost, b1)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] +\n",
    "    [(dW1, update_dW1), (dW2, update_dW2),(db2, update_db2), (db1, update_db1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 4: training the model  \n",
    "\n",
    "When we execute our model with momentum incorporated, the advantage becomes apparent immediately, our solution converges much master our a lower error rate of 0.03. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 2325.724 / 0.839\n",
      "Cost / err at iteration i=2, j=0: 218.201 / 0.060\n",
      "Cost / err at iteration i=4, j=0: 166.388 / 0.049\n",
      "Cost / err at iteration i=6, j=0: 142.304 / 0.044\n",
      "Cost / err at iteration i=8, j=0: 129.169 / 0.039\n",
      "Cost / err at iteration i=10, j=0: 120.625 / 0.034\n",
      "Cost / err at iteration i=12, j=0: 114.360 / 0.033\n",
      "Cost / err at iteration i=14, j=0: 109.979 / 0.031\n",
      "Cost / err at iteration i=16, j=0: 107.022 / 0.030\n",
      "Cost / err at iteration i=18, j=0: 105.149 / 0.029\n",
      "Cost / err at iteration i=20, j=0: 103.811 / 0.029\n",
      "Cost / err at iteration i=22, j=0: 103.053 / 0.028\n",
      "Cost / err at iteration i=24, j=0: 102.454 / 0.028\n",
      "Cost / err at iteration i=26, j=0: 102.201 / 0.028\n",
      "Cost / err at iteration i=28, j=0: 102.222 / 0.027\n",
      "Cost / err at iteration i=29, j=0: 102.278 / 0.028\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5128d475f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LL = []\n",
    "for i in range(max_iter):\n",
    "    #Xtrain, Ytrain_ind = shuffle(Xtrain, Ytrain_ind)\n",
    "    for j in range(int(n_batches)):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            LL.append(cost_val)\n",
    "            if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err))\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# With RMSProp  \n",
    "\n",
    "[RMSProp](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) (for Root Mean Square Propagation) is a method in which the learning rate is adapted for each of the parameters. The idea is to divide the learning rate for a weight by a running average of the magnitudes of recent gradients for that weight. So, first the running average, or cache, is calculated in terms of means square,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\\begin{align}\n",
    "\\ v(w,t) := \\gamma v(w, t-1)+(1-\\gamma)(\\bigtriangledown Q_i(w))^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "where gamma is the forgetting factor or decay rate.\n",
    "\n",
    "The parameters are updates as,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\\begin{align}\n",
    "\\ w := w - \\frac{\\eta}{\\sqrt{v(w,t)}}\\bigtriangledown Q_i(w)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or, in pseudo-code:  \n",
    "`cache = decay_rate*cache + (1 - decay_rate)*gradient^2  \n",
    "w -= learning_rate*gradient / (sqrt(cache) + epsilon)  \n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 1: get the data and define our key variables  \n",
    "\n",
    "In order to incorporate RMSProp into our model, we need to first define our decay rate, which we will initially set as 0.999, and we wil also add a small non-zero value for epsilon so that we are not dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data(data)\n",
    "\n",
    "max_iter = 30\n",
    "print_period = 10\n",
    "\n",
    "lr = np.float32(0.001)\n",
    "reg = np.float32(10e-12)\n",
    "decay_rate = np.float32(.999)\n",
    "eps = np.float32(0.0000000001) # so that we don't divide by zero\n",
    "\n",
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "\n",
    "M = 300\n",
    "K = 10\n",
    "W1_init = np.random.randn(D, M) / 28\n",
    "cache_W1_init = np.zeros((D, M))\n",
    "b1_init = np.zeros(M)\n",
    "cache_b1_init = np.zeros(M)\n",
    "W2_init = np.random.randn(M, K) / np.sqrt(M)\n",
    "cache_W2_init = np.zeros((M, K))\n",
    "b2_init = np.zeros(K)\n",
    "cache_b2_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2: define theano variables and expressions  \n",
    "\n",
    "Next, we need to create variables that keep track of the cache of our recent gradients. Above, we created matrices of zeroes with which we will initialize our new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 2: define theano variables and expressions\n",
    "\n",
    "# inputs\n",
    "thX = T.matrix('X')\n",
    "\n",
    "# targets\n",
    "thT = T.matrix('T')\n",
    "\n",
    "# input-to-hidden-layer weights and bias\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "cache_W1 = theano.shared(cache_W1_init, 'cache_W1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "cache_b1 = theano.shared(cache_b1_init, 'cache_b1')\n",
    "\n",
    "# hidden-layer-to-output weights and bias\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "cache_W2 = theano.shared(cache_W2_init, 'cache_W2')\n",
    "b2 = theano.shared(b2_init, 'b2')\n",
    "cache_b2 = theano.shared(cache_b2_init, 'cache_b2')\n",
    "\n",
    "# we can use the built-in theano functions to do relu and softmax\n",
    "thZ = T.nnet.relu( thX.dot(W1) + b1 ) # relu is new in version 0.7.1 but just in case you don't have it\n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n",
    "\n",
    "# define the cost function and prediction (theano automatically does the differentiation)\n",
    "cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2).sum())\n",
    "prediction = T.argmax(thY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 3: define training expressions and functions  \n",
    "\n",
    "The new shared variables (our cached gradients) will be updated through each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "update_cache_W2 = decay_rate*cache_W2 + (np.float32(1) - decay_rate)*T.grad(cost, W2)*T.grad(cost, W2)\n",
    "update_W2 = W2  - lr*T.grad(cost, W2) / (T.sqrt(cache_W2) + eps)\n",
    "\n",
    "update_cache_b2 = decay_rate*cache_b2 + (np.float32(1) - decay_rate)*T.grad(cost, b2)*T.grad(cost, b2)\n",
    "update_b2 = b2  - lr*T.grad(cost, b2) / (T.sqrt(cache_b2) + eps)\n",
    "\n",
    "update_cache_W1 = decay_rate*cache_W1 + (np.float32(1) - decay_rate)*T.grad(cost, W1)*T.grad(cost, W1)\n",
    "update_W1 = W1  - lr*T.grad(cost, W1) / (T.sqrt(cache_W1) + eps)\n",
    "\n",
    "update_cache_b1 = decay_rate*cache_b1 + (np.float32(1) - decay_rate)*T.grad(cost, b1)*T.grad(cost, b1)\n",
    "update_b1 = b1  - lr*T.grad(cost, b1) / (T.sqrt(cache_b1) + eps)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(cache_W1, update_cache_W1), (cache_W2, update_cache_W2), \n",
    "             (cache_b1, update_cache_b1), (cache_b2, update_cache_b2)]   \n",
    ")\n",
    "\n",
    "train2 = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 4: training the model  \n",
    "\n",
    "When we execute our model with momentum incorporated, the advantage becomes apparent immediately, our solution is comparable to the one we achieved with momentum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 2482.705 / 0.389\n",
      "Cost / err at iteration i=2, j=0: 115.293 / 0.031\n",
      "Cost / err at iteration i=4, j=0: 106.673 / 0.025\n",
      "Cost / err at iteration i=6, j=0: 102.615 / 0.026\n",
      "Cost / err at iteration i=8, j=0: 103.861 / 0.025\n",
      "Cost / err at iteration i=10, j=0: 108.116 / 0.026\n",
      "Cost / err at iteration i=12, j=0: 111.520 / 0.026\n",
      "Cost / err at iteration i=14, j=0: 114.464 / 0.027\n",
      "Cost / err at iteration i=16, j=0: 117.215 / 0.027\n",
      "Cost / err at iteration i=18, j=0: 120.086 / 0.027\n",
      "Cost / err at iteration i=20, j=0: 122.561 / 0.027\n",
      "Cost / err at iteration i=22, j=0: 125.061 / 0.026\n",
      "Cost / err at iteration i=24, j=0: 127.337 / 0.026\n",
      "Cost / err at iteration i=26, j=0: 129.465 / 0.026\n",
      "Cost / err at iteration i=28, j=0: 131.443 / 0.026\n",
      "Cost / err at iteration i=29, j=0: 132.381 / 0.026\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f511b76a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LL = []\n",
    "for i in range(max_iter):\n",
    "    #Xtrain, Ytrain_ind = shuffle(Xtrain, Ytrain_ind)\n",
    "    for j in range(int(n_batches)):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        train2(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            LL.append(cost_val)\n",
    "            if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err))\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# With RMSProp and Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When we combine RMSProp and momentum, we see that our error rate is actually higher than the models with only RMSProp or momentum. This is an indication that our hyperparameters need tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 1: get the data and define all the usual variables\n",
    "X, Y = get_normalized_data(data)\n",
    "\n",
    "max_iter = 30\n",
    "print_period = 10\n",
    "\n",
    "lr = np.float32(10e-7)\n",
    "reg = np.float32(10-12)\n",
    "mu = np.float32(0.99)\n",
    "decay_rate = np.float32(.999)\n",
    "eps = np.float32(0.0000000001) # so that we don't divide by zero\n",
    "\n",
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N / batch_sz\n",
    "\n",
    "M = 300\n",
    "K = 10\n",
    "W1_init = np.random.randn(D, M) / 28\n",
    "dW1_init = np.zeros((D, M))\n",
    "cache_W1_init = np.zeros((D, M))\n",
    "b1_init = np.zeros(M)\n",
    "db1_init = np.zeros(M)\n",
    "cache_b1_init = np.zeros(M)\n",
    "W2_init = np.random.randn(M, K) / np.sqrt(M)\n",
    "dW2_init = np.zeros((M, K))\n",
    "cache_W2_init = np.zeros((M, K))\n",
    "b2_init = np.zeros(K)\n",
    "db2_init = np.zeros(K)\n",
    "cache_b2_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41000, 784)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 2: define theano variables and expressions\n",
    "\n",
    "# inputs\n",
    "thX = T.matrix('X')\n",
    "\n",
    "# targets\n",
    "thT = T.matrix('T')\n",
    "\n",
    "# input-to-hidden-layer weights and bias\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "dW1 = theano.shared(dW1_init, 'dW1')\n",
    "cache_W1 = theano.shared(cache_W1_init, 'cache_W1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "db1 = theano.shared(db1_init, 'db1')\n",
    "cache_b1 = theano.shared(cache_b1_init, 'cache_b1')\n",
    "\n",
    "# hidden-layer-to-output weights and bias\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "dW2 = theano.shared(dW2_init, 'dW2')\n",
    "cache_W2 = theano.shared(cache_W2_init, 'cache_W2')\n",
    "b2 = theano.shared(b2_init, 'b2')\n",
    "db2 = theano.shared(db2_init, 'db2')\n",
    "cache_b2 = theano.shared(cache_b2_init, 'cache_b2')\n",
    "\n",
    "# we can use the built-in theano functions to do relu and softmax\n",
    "thZ = T.nnet.relu( thX.dot(W1) + b1 ) # relu is new in version 0.7.1 but just in case you don't have it\n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n",
    "\n",
    "# define the cost function and prediction (theano automatically does the differentiation)\n",
    "cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2).sum())\n",
    "prediction = T.argmax(thY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "update_dW2 = mu*dW2 - lr*T.grad(cost, W2) / (T.sqrt(cache_W2) + eps)\n",
    "update_cache_W2 = decay_rate*cache_W2 + (np.float32(1) - decay_rate)*T.grad(cost, W2)*T.grad(cost, W2)\n",
    "update_W2 = W2 + mu*dW2 - lr*T.grad(cost, W2) / (T.sqrt(cache_W2) + eps)\n",
    "\n",
    "\n",
    "update_db2 = mu*db2 - lr*T.grad(cost, b2) / (T.sqrt(cache_b2) + eps)\n",
    "update_cache_b2 = decay_rate*cache_b2 + (np.float32(1) - decay_rate)*T.grad(cost, b2)*T.grad(cost, b2)\n",
    "update_b2 = b2 + mu*db2 - lr*T.grad(cost, b2) / (T.sqrt(cache_b2) + eps)\n",
    "\n",
    "update_dW1 = mu*dW1 - lr*T.grad(cost, W1) / (T.sqrt(cache_W1) + eps)\n",
    "update_cache_W1 = decay_rate*cache_W1 + (np.float32(1) - decay_rate)*T.grad(cost, W1)*T.grad(cost, W1)\n",
    "update_W1 = W1 + mu*dW1 - lr*T.grad(cost, W1) / (T.sqrt(cache_W1) + eps)\n",
    "\n",
    "update_db1 = mu*db1 - lr*T.grad(cost, b1) / (T.sqrt(cache_b1) + eps)\n",
    "update_cache_b1 = decay_rate*cache_b1 + (np.float32(1) - decay_rate)*T.grad(cost, b1)*T.grad(cost, b1)\n",
    "update_b1 = b1 + mu*db1 - lr*T.grad(cost, b1) / (T.sqrt(cache_b1) + eps)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(cache_W1, update_cache_W1), (cache_W2, update_cache_W2), \n",
    "             (cache_b1, update_cache_b1), (cache_b2, update_cache_b2)]\n",
    ")\n",
    "\n",
    "train2 = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates=[(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] +\n",
    "    [(dW1, update_dW1), (dW2, update_dW2),(db2, update_db2), (db1, update_db1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 1891.141 / 0.911\n",
      "Cost / err at iteration i=2, j=0: -992.135 / 0.111\n",
      "Cost / err at iteration i=4, j=0: -2633.315 / 0.084\n",
      "Cost / err at iteration i=6, j=0: -4676.145 / 0.074\n",
      "Cost / err at iteration i=8, j=0: -7008.585 / 0.068\n",
      "Cost / err at iteration i=10, j=0: -9627.492 / 0.060\n",
      "Cost / err at iteration i=12, j=0: -12562.862 / 0.055\n",
      "Cost / err at iteration i=14, j=0: -15842.929 / 0.054\n",
      "Cost / err at iteration i=16, j=0: -19492.394 / 0.052\n",
      "Cost / err at iteration i=18, j=0: -23530.431 / 0.049\n",
      "Cost / err at iteration i=20, j=0: -27969.247 / 0.048\n",
      "Cost / err at iteration i=22, j=0: -32813.259 / 0.046\n",
      "Cost / err at iteration i=24, j=0: -38066.610 / 0.045\n",
      "Cost / err at iteration i=26, j=0: -43731.936 / 0.042\n",
      "Cost / err at iteration i=28, j=0: -49807.704 / 0.043\n",
      "Cost / err at iteration i=29, j=0: -52997.533 / 0.043\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkVJTeIiISKkpPEREpNT+H48sVsXmTp3eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f511cd370f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LL = []\n",
    "for i in range(max_iter):\n",
    "    #Xtrain, Ytrain_ind = shuffle(Xtrain, Ytrain_ind)\n",
    "    for j in range(int(n_batches)):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        train2(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            LL.append(cost_val)\n",
    "            if (i % 2 == 0 or i % 29 == 0) and j % 100 == 0:\n",
    "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err))\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
