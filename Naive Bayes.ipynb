{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "## Model Summary\n",
    "\n",
    "The Naive Bayes Classifier is an algorithm based on Baye's Theorem, which can be represented as:\n",
    "\n",
    "![Title](extras/bayes_rule.png)\n",
    "\n",
    "where:\n",
    " - P(c|x) is the posterior probability of class (c, or outcome variable) given predictor (x, or attributes or features).\n",
    " - P(x|c) is the likelihood/probability of the predictor occuring given class.\n",
    " - P(c) is the prior probability of class (overall probability that it occurs).\n",
    " - P(x) is the prior probability of predictor (also known as 'evidence' in Bayesian probability terminology).\n",
    "\n",
    "The conditional probabilities are then multiplied across all features for each class, and the class with the highest probability is chosen. It is very important to note that a key assumption of this model is that the features are independent, which is where the _naive_ name is derived.\n",
    "\n",
    "## Theoretical Example\n",
    "\n",
    "Let us predict the probability that a phone will explode given that it's a Samsung Note, P(c|x). If 1% of all phones explode, 25% of all phones are Samsung Note, and 75% of all exploding phones are Samsung Note, then P(c|x) is ((.75)(.25))/(.01) = 18.75%.\n",
    "\n",
    "## Pros & Cons\n",
    "\n",
    "Pros:\n",
    " - It is a very fast classifier.\n",
    " - It performs well with categorical input variables compared to numerical ones.\n",
    "\n",
    "Cons:\n",
    " - If a categorical variable has a value that is observed in the Test data set that didn't exist in the Training data set, the model assumes a zero probability and cannot make a prediction. This can be fixed using the Laplace estimation smoothing technique.\n",
    " - The model is known to be a bad predictor, meaning outputs from predict_proba are worthless.\n",
    " - The assumptions of independent features or normal distribution in the Gaussian NB model are very strong.\n",
    "  \n",
    "## Applications\n",
    "\n",
    " - Real time prediction: NB is a very fast classifier. \n",
    " - Multi-class prediction\n",
    " - Text Classification\n",
    " - Recommender Systems: NB is often used with Collaborative Filtering to build good recommender systems.\n",
    "\n",
    "## Model Types\n",
    "\n",
    "There are three primary Naive Bayes models, each determined by the kind of feature variables we're working with: \n",
    " - Gaussian NB: assumes that the features are numerical follow a normal distribution.\n",
    " - Multinomial NB: assumes that the feature variables are discrete counts, and is often used in text classification that analyzes word counts.\n",
    " - Bernoulli NB: assumes that the features are binary variables, and is often used in text classification that looks for the presence of a given word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Classification Coding Example\n",
    "\n",
    "In this example, we will use the Bernoulli classification model to predict the _Gender_ of an ASU PSC applicant using the _Military_ and _Ethnicity_ fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data (available on Kaggle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the quick inspection of columns, we cna take Pclass, Sex, and Embarked as our categorical predictors, which we will turn into binary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.concat([pd.get_dummies(data[['Sex', 'Embarked']]),pd.get_dummies(data['Pclass'])], axis=1)\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model using a Bernoulli Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138  31]\n",
      " [ 35  91]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.82      0.81       169\n",
      "          1       0.75      0.72      0.73       126\n",
      "\n",
      "avg / total       0.78      0.78      0.78       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = nb.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test, yhat)\n",
    "print '\\n', classification_report(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    " - http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n",
    " - https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    " - http://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    " - Add examples of Gaussian and Multinomial models\n",
    " - Answer question: what happens if the assumption of independent features is violated?\n",
    " - Answer question: what happens if features are both numerical _and_ categorical?\n",
    " - Answer question (not necessarily just NB): in which modeling techniques do we _have to_ drop a category value when creating dummy variables?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
